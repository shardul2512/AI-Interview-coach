{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shardul2512/AI-Interview-coach/blob/main/AI_Coding_Interview_Agent_(Python).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import sys # Added for Colab check\n",
        "from dotenv import load_dotenv\n",
        "from typing import List, Optional\n",
        "\n",
        "# Langchain components\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
        "# Use pydantic.v1 for compatibility\n",
        "from pydantic.v1 import BaseModel, Field, validator\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter # Optional\n",
        "\n",
        "# --- Pydantic Models for Structured Output ---\n",
        "\n",
        "class Skill(BaseModel):\n",
        "    \"\"\"Represents a single skill extracted from the resume.\"\"\"\n",
        "    name: str = Field(description=\"Name of the skill (e.g., Python, React, SQL)\")\n",
        "    category: Optional[str] = Field(description=\"Category (e.g., Language, Framework, Tool, Database)\", default=\"Uncategorized\")\n",
        "\n",
        "class Project(BaseModel):\n",
        "    \"\"\"Represents a project described in the resume.\"\"\"\n",
        "    name: str = Field(description=\"Name of the project\")\n",
        "    description: str = Field(description=\"Brief description of the project and the candidate's role/contributions\")\n",
        "    technologies: Optional[List[str]] = Field(description=\"List of key technologies used\", default=[])\n",
        "\n",
        "class WorkExperience(BaseModel):\n",
        "    \"\"\"Represents a work experience entry from the resume.\"\"\"\n",
        "    company: str = Field(description=\"Company name\")\n",
        "    role: str = Field(description=\"Job title/role\")\n",
        "    duration: Optional[str] = Field(description=\"Dates of employment (e.g., 'Jan 2020 - Dec 2022')\", default=\"N/A\")\n",
        "    responsibilities: Optional[List[str]] = Field(description=\"List of key responsibilities or achievements\", default=[])\n",
        "\n",
        "class ResumeData(BaseModel):\n",
        "    \"\"\"Overall structure for the parsed resume data.\"\"\"\n",
        "    summary: Optional[str] = Field(description=\"Brief professional summary if available, otherwise empty string\", default=\"\")\n",
        "    skills: Optional[List[Skill]] = Field(description=\"List of technical skills\", default=[])\n",
        "    projects: Optional[List[Project]] = Field(description=\"List of personal or academic projects\", default=[])\n",
        "    work_experience: Optional[List[WorkExperience]] = Field(description=\"List of professional work experiences\", default=[])\n",
        "    candidate_name: Optional[str] = Field(description=\"Name of the candidate if found\", default=\"Candidate\") # Added field\n",
        "\n",
        "    # Add validator to handle potential None values during parsing if needed\n",
        "    @validator('skills', 'projects', 'work_experience', pre=True, always=True)\n",
        "    def ensure_list(cls, v):\n",
        "        return v if v is not None else []\n",
        "\n",
        "# --- Core Functions ---\n",
        "\n",
        "# Updated load_api_key function\n",
        "def load_api_key():\n",
        "    \"\"\"Loads the Google API key, checking .env file first, then Colab secrets.\"\"\"\n",
        "    api_key = None\n",
        "    try:\n",
        "        load_dotenv()\n",
        "        api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    except Exception as e:\n",
        "        print(f\"Note: Error loading .env file (this is expected in Colab if no .env exists): {e}\")\n",
        "\n",
        "    if not api_key:\n",
        "        print(\"API key not found in environment variables or .env file. Trying Colab secrets...\")\n",
        "        # Try loading from Colab secrets as a fallback\n",
        "        try:\n",
        "            from google.colab import userdata\n",
        "            api_key = userdata.get('GOOGLE_API_KEY')\n",
        "            if api_key:\n",
        "                print(\"API key loaded successfully from Colab secrets.\")\n",
        "                # Set environment variable for potential downstream use (optional but good practice)\n",
        "                os.environ['GOOGLE_API_KEY'] = api_key\n",
        "            else:\n",
        "                 print(\"API key not found in Colab secrets.\")\n",
        "        except ImportError:\n",
        "            # Not running in Colab or Colab userdata is unavailable\n",
        "            print(\"Not in a Colab environment or google.colab.userdata failed.\")\n",
        "            api_key = None\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading from Colab secrets: {e}\")\n",
        "            api_key = None\n",
        "\n",
        "    if not api_key: # If still not found after checking both\n",
        "        raise ValueError(\"GOOGLE_API_KEY not found. Please create a .env file or add the secret 'GOOGLE_API_KEY' in Colab with Notebook access enabled.\")\n",
        "\n",
        "    return api_key\n",
        "\n",
        "\n",
        "# Updated initialize_llm function\n",
        "def initialize_llm(api_key):\n",
        "    \"\"\"Initializes the Gemini LLM.\"\"\"\n",
        "    # Using ChatGoogleGenerativeAI for conversational abilities\n",
        "    # Adjust temperature: 0.0-0.3 for factual tasks (extraction), 0.5-0.7 for creative tasks (generation)\n",
        "    # Use the standard model name \"gemini-1.0-pro\" instead of \"gemini-pro\"\n",
        "    print(\"Initializing LLM with model: gemini-2.0-flash\") # Added print statement\n",
        "    return ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=api_key, request_timeout=120)\n",
        "\n",
        "def load_resume_text(pdf_path):\n",
        "    \"\"\"Loads text content from a PDF file.\"\"\"\n",
        "    try:\n",
        "        loader = PyPDFLoader(pdf_path)\n",
        "        # load_and_split() can be used if chunking is needed, but load() is simpler for moderate resumes\n",
        "        docs = loader.load()\n",
        "        full_text = \"\\n\".join([doc.page_content for doc in docs])\n",
        "        if not full_text.strip():\n",
        "             raise ValueError(\"Could not extract text from PDF. Ensure it's text-based.\")\n",
        "        return full_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading PDF {pdf_path}: {e}\")\n",
        "        raise\n",
        "\n",
        "def create_extraction_chain(llm):\n",
        "    \"\"\"Creates the Langchain chain for extracting structured data from resume text.\"\"\"\n",
        "    parser = JsonOutputParser(pydantic_object=ResumeData)\n",
        "\n",
        "    extraction_prompt_template = \"\"\"\n",
        "    You are an expert resume parser. Analyze the following resume text and extract the information precisely according to the provided JSON schema.\n",
        "    Focus on:\n",
        "    - Candidate's Name (if clearly identifiable)\n",
        "    - Professional Summary/Objective (if present)\n",
        "    - Work Experiences (Company, Role, Duration, Key Responsibilities/Achievements)\n",
        "    - Projects (Name, Description, Technologies Used)\n",
        "    - Technical Skills (Name and attempt to categorize: Language, Framework, Tool, Database, Concept, etc.)\n",
        "\n",
        "    If information for a field is missing or unclear, use default values specified in the schema (like empty lists or strings, or 'N/A', 'Uncategorized'). Be accurate.\n",
        "\n",
        "    Schema:\n",
        "    {schema}\n",
        "\n",
        "    Resume Text:\n",
        "    ---\n",
        "    {resume_text}\n",
        "    ---\n",
        "\n",
        "    Extracted JSON:\n",
        "    \"\"\"\n",
        "    extraction_prompt = ChatPromptTemplate.from_template(\n",
        "        extraction_prompt_template,\n",
        "        partial_variables={\"schema\": ResumeData.schema_json(indent=2)}\n",
        "    )\n",
        "\n",
        "    # Chain: Prompt -> LLM -> JSON Parser\n",
        "    return extraction_prompt | llm | parser\n",
        "\n",
        "def parse_resume(pdf_path, llm):\n",
        "    \"\"\"Loads and parses the resume PDF to extract structured data.\"\"\"\n",
        "    print(f\"Loading resume: {pdf_path}\")\n",
        "    resume_text = load_resume_text(pdf_path)\n",
        "    print(\"Resume text loaded, starting extraction...\")\n",
        "    extraction_chain = create_extraction_chain(llm)\n",
        "    try:\n",
        "        # Invoke the chain with the resume text\n",
        "        print(\"Invoking extraction chain...\") # Added print statement\n",
        "        extracted_data_dict = extraction_chain.invoke({\"resume_text\": resume_text})\n",
        "        print(\"Extraction chain finished.\") # Added print statement\n",
        "        # Validate with Pydantic model\n",
        "        # Use ** unpacking for pydantic v1/v2 compatibility\n",
        "        validated_data = ResumeData(**extracted_data_dict)\n",
        "        print(\"Resume parsed successfully.\")\n",
        "        return validated_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error during resume parsing or validation: {e}\")\n",
        "        # Fallback or re-try logic could be added here\n",
        "        raise # Re-raise the exception to stop execution if parsing fails\n",
        "\n",
        "\n",
        "# --- Interview Session Class ---\n",
        "\n",
        "class InterviewSession:\n",
        "    \"\"\"Manages the state and flow of the simulated interview.\"\"\"\n",
        "\n",
        "    def __init__(self, resume_data: ResumeData, llm):\n",
        "        \"\"\"Initializes the session with resume data and the LLM.\"\"\"\n",
        "        self.resume_data = resume_data\n",
        "        self.llm = llm # Use the shared LLM instance\n",
        "        self.history = [] # Stores (agent_type, question, answer, evaluation) dicts\n",
        "        self.candidate_name = resume_data.candidate_name or \"Candidate\"\n",
        "\n",
        "        # --- Chains for different agents ---\n",
        "        self._setup_agent_chains()\n",
        "\n",
        "    def _setup_agent_chains(self):\n",
        "        \"\"\"Initializes Langchain chains for each interview agent.\"\"\"\n",
        "        # --- Behavioral Question Generation Chain ---\n",
        "        behavioral_question_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are a professional interviewer starting a behavioral interview section.\n",
        "            Based on the candidate's resume details below, generate ONE relevant behavioral question.\n",
        "            Focus on their experiences and projects. Ask \"Tell me about a time...\" or \"Describe a situation...\" questions.\n",
        "            Alternatively, ask a standard behavioral question (strengths, weaknesses, teamwork, conflict resolution).\n",
        "            AVOID asking questions that were already asked in the 'Previous Questions' list.\n",
        "\n",
        "            Candidate Name: {candidate_name}\n",
        "            Resume Summary: {summary}\n",
        "            Work Experience: {work_experience}\n",
        "            Projects: {projects}\n",
        "            Previous Questions:\n",
        "            {previous_questions}\n",
        "\n",
        "            Generate ONE behavioral question for {candidate_name}:\"\"\"\n",
        "        )\n",
        "        self.behavioral_question_chain = behavioral_question_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        # --- Coding Question Generation Chain ---\n",
        "        coding_question_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are a technical interviewer preparing a coding-related question.\n",
        "            Based on the candidate's skills, ask ONE conceptual question about algorithms, data structures, language features, or problem-solving approaches relevant to their skills.\n",
        "            DO NOT ask for live code implementation. Focus on understanding and explanation.\n",
        "            Example: \"Considering your Python skills, explain the difference between lists and tuples and when you'd use each.\" or \"How would you approach optimizing a database query if you noticed slow performance, given your SQL experience?\"\n",
        "            AVOID asking questions that were already asked in the 'Previous Questions' list.\n",
        "\n",
        "            Candidate Name: {candidate_name}\n",
        "            Skills: {skills}\n",
        "            Previous Questions:\n",
        "            {previous_questions}\n",
        "\n",
        "            Generate ONE conceptual coding question for {candidate_name}:\"\"\"\n",
        "        )\n",
        "        self.coding_question_chain = coding_question_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        # --- System Design Chain Removed ---\n",
        "\n",
        "        # --- Answer Evaluation Chain ---\n",
        "        evaluation_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are an interview coach evaluating a candidate's answer during an interview simulation.\n",
        "            Provide brief, constructive feedback (2-3 sentences). Focus on clarity, relevance, structure (like STAR for behavioral), depth, and technical accuracy (where applicable).\n",
        "            Be encouraging but also point out specific areas for improvement if needed.\n",
        "\n",
        "            Interview Stage: {question_type}\n",
        "            Question Asked: {question}\n",
        "            Candidate's Answer: {answer}\n",
        "\n",
        "            Provide feedback on the answer:\"\"\"\n",
        "        )\n",
        "        self.evaluation_chain = evaluation_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "        # --- Final Feedback Synthesis Chain ---\n",
        "        # Note: The final feedback prompt still mentions System Design, but it will be based on empty history for that section.\n",
        "        final_feedback_prompt = ChatPromptTemplate.from_template(\n",
        "            \"\"\"You are an experienced hiring manager summarizing the performance of {candidate_name} in a simulated technical interview.\n",
        "            Review the entire interview history provided below, including questions, answers, and individual evaluations.\n",
        "            Synthesize this into comprehensive, constructive feedback.\n",
        "\n",
        "            Structure the feedback clearly:\n",
        "            1.  **Overall Summary:** Brief overview of performance.\n",
        "            2.  **Behavioral Section:** Strengths and areas for improvement.\n",
        "            3.  **Technical Concepts/Coding Section:** Strengths and areas for improvement.\n",
        "            4.  **System Design Section:** Strengths and areas for improvement (will likely state no questions asked).\n",
        "            5.  **Key Recommendations:** Actionable advice for the candidate.\n",
        "\n",
        "            Be professional, balanced, and encouraging.\n",
        "\n",
        "            Full Interview History:\n",
        "            ---\n",
        "            {interview_history}\n",
        "            ---\n",
        "\n",
        "            Generate Comprehensive Final Feedback for {candidate_name}:\"\"\"\n",
        "        )\n",
        "        self.final_feedback_chain = final_feedback_prompt | self.llm | StrOutputParser()\n",
        "\n",
        "\n",
        "    def _get_previous_questions(self, agent_type=None):\n",
        "        \"\"\"Helper to get questions already asked, optionally filtered by agent type.\"\"\"\n",
        "        qs = []\n",
        "        for item in self.history:\n",
        "            if agent_type is None or item['agent'] == agent_type:\n",
        "                qs.append(item['question'])\n",
        "        return \"\\n\".join(f\"- {q}\" for q in qs) if qs else \"None\"\n",
        "\n",
        "    def add_interaction(self, agent_type, question, answer, evaluation):\n",
        "        \"\"\"Adds a question-answer-evaluation cycle to the history.\"\"\"\n",
        "        self.history.append({\n",
        "            \"agent\": agent_type,\n",
        "            \"question\": question,\n",
        "            \"answer\": answer,\n",
        "            \"evaluation\": evaluation\n",
        "        })\n",
        "        print(\"-\" * 20) # Separator after each interaction feedback\n",
        "\n",
        "    def evaluate_answer(self, question, answer, question_type):\n",
        "        \"\"\"Uses the LLM chain to evaluate the candidate's answer.\"\"\"\n",
        "        print(\"\\nInterviewer: Thinking...\") # Simulate evaluation time\n",
        "        feedback = self.evaluation_chain.invoke({\n",
        "            \"question_type\": question_type,\n",
        "            \"question\": question,\n",
        "            \"answer\": answer\n",
        "        })\n",
        "        print(f\"Interviewer Feedback: {feedback}\")\n",
        "        return feedback\n",
        "\n",
        "    # --- Agent Interaction Methods ---\n",
        "\n",
        "    def ask_behavioral_question(self):\n",
        "        \"\"\"Generates and asks a behavioral question.\"\"\"\n",
        "        print(\"\\n--- Behavioral Question ---\")\n",
        "        previous_qs = self._get_previous_questions('behavioral')\n",
        "        # Prepare context for the prompt\n",
        "        # Ensure resume data components are not None before accessing .dict() or converting\n",
        "        work_exp_list = self.resume_data.work_experience if self.resume_data.work_experience else []\n",
        "        projects_list = self.resume_data.projects if self.resume_data.projects else []\n",
        "        context = {\n",
        "            \"candidate_name\": self.candidate_name,\n",
        "            \"summary\": self.resume_data.summary or \"N/A\",\n",
        "            # Convert lists of objects to simpler string representations for the prompt\n",
        "            \"work_experience\": json.dumps([exp.dict(exclude_none=True) for exp in work_exp_list], indent=2),\n",
        "            \"projects\": json.dumps([p.dict(exclude_none=True) for p in projects_list], indent=2),\n",
        "            \"previous_questions\": previous_qs\n",
        "        }\n",
        "        question = self.behavioral_question_chain.invoke(context)\n",
        "        print(f\"Interviewer: {question}\")\n",
        "        answer = input(f\"{self.candidate_name}'s Answer: \")\n",
        "        evaluation = self.evaluate_answer(question, answer, \"Behavioral\")\n",
        "        self.add_interaction(\"behavioral\", question, answer, evaluation)\n",
        "\n",
        "    def ask_coding_question(self):\n",
        "        \"\"\"Generates and asks a conceptual coding question.\"\"\"\n",
        "        print(\"\\n--- Technical/Coding Concept Question ---\")\n",
        "        previous_qs = self._get_previous_questions('coding')\n",
        "        skills_list = [f\"{s.name} ({s.category})\" for s in self.resume_data.skills] if self.resume_data.skills else [\"General Concepts\"]\n",
        "        context = {\n",
        "             \"candidate_name\": self.candidate_name,\n",
        "             \"skills\": \", \".join(skills_list),\n",
        "             \"previous_questions\": previous_qs\n",
        "        }\n",
        "        question = self.coding_question_chain.invoke(context)\n",
        "        print(f\"Interviewer: {question}\")\n",
        "        answer = input(f\"{self.candidate_name}'s Approach/Explanation: \")\n",
        "        evaluation = self.evaluate_answer(question, answer, \"Coding/Concepts\")\n",
        "        self.add_interaction(\"coding\", question, answer, evaluation)\n",
        "\n",
        "    # --- ask_system_design_question method removed ---\n",
        "\n",
        "    # --- Final Feedback ---\n",
        "\n",
        "    def generate_final_feedback(self):\n",
        "        \"\"\"Generates and prints the overall interview feedback.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*25 + \" Generating Final Feedback \" + \"=\"*25)\n",
        "        if not self.history:\n",
        "            print(\"No interview interactions recorded to generate feedback.\")\n",
        "            return\n",
        "\n",
        "        # Format history for the prompt\n",
        "        history_str = \"\\n\\n\".join([\n",
        "            f\"**{item['agent'].upper()} Stage**\\n\"\n",
        "            f\"Q: {item['question']}\\n\"\n",
        "            f\"A: {item['answer']}\\n\"\n",
        "            f\"Feedback: {item['evaluation']}\"\n",
        "            for item in self.history\n",
        "        ])\n",
        "\n",
        "        final_feedback = self.final_feedback_chain.invoke({\n",
        "            \"candidate_name\": self.candidate_name,\n",
        "            \"interview_history\": history_str\n",
        "        })\n",
        "\n",
        "        print(\"\\n\" + \"=\"*20 + f\" Final Interview Feedback for {self.candidate_name} \" + \"=\"*20)\n",
        "        print(final_feedback)\n",
        "        print(\"=\"* (42 + len(self.candidate_name) + 1)) # Match closing border width\n",
        "        return final_feedback\n",
        "\n",
        "\n",
        "# --- Main Execution Logic ---\n",
        "\n",
        "def run_interview(pdf_path):\n",
        "    \"\"\"Orchestrates the entire interview process.\"\"\"\n",
        "    try:\n",
        "        # 1. Setup\n",
        "        # api_key is loaded globally now, llm initialized globally\n",
        "        api_key = load_api_key() # Ensure API key is loaded\n",
        "        llm = initialize_llm(api_key) # Initialize LLM with the key\n",
        "\n",
        "        # 2. Parse Resume\n",
        "        resume_data = parse_resume(pdf_path, llm)\n",
        "\n",
        "        # 3. Initialize Interview Session\n",
        "        session = InterviewSession(resume_data, llm)\n",
        "        print(f\"\\nStarting Interview Simulation for {session.candidate_name}...\")\n",
        "        print(\"=\"*30)\n",
        "\n",
        "        # 4. Define Interview Flow (customize as needed)\n",
        "        # System Design question removed from the flow\n",
        "        interview_stages = [\n",
        "            session.ask_behavioral_question,\n",
        "            session.ask_coding_question,\n",
        "            session.ask_behavioral_question, # Ask another behavioral\n",
        "            # session.ask_system_design_question, # <--- REMOVED\n",
        "            # Add more stages (e.g., another coding question) if desired\n",
        "        ]\n",
        "\n",
        "        # 5. Run Interview Stages\n",
        "        for stage_func in interview_stages:\n",
        "            try:\n",
        "                stage_func()\n",
        "            except Exception as e:\n",
        "                print(f\"\\n!! An error occurred during stage {stage_func.__name__}: {e}\")\n",
        "                print(\"Attempting to continue interview...\")\n",
        "                # Decide if the error is fatal or if you can skip the stage\n",
        "\n",
        "        # 6. Generate Final Feedback\n",
        "        session.generate_final_feedback()\n",
        "\n",
        "        print(\"\\nInterview Simulation Complete.\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"\\nConfiguration Error: {ve}\") # This is where the error originates\n",
        "    except FileNotFoundError:\n",
        "        print(f\"\\nError: Resume PDF file not found at {pdf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\") # Catch other errors like the 404\n",
        "\n",
        "\n",
        "# --- Script Entry Point ---\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Configuration ---\n",
        "    # IMPORTANT: Replace this placeholder with the actual path to the candidate's resume PDF\n",
        "    # Example for Colab if file 'Sresume.pdf' is uploaded to root:\n",
        "    resume_pdf_path = \"Sresume.pdf\"\n",
        "    # Example for local machine:\n",
        "    # resume_pdf_path = \"/path/on/your/computer/Sresume.pdf\"\n",
        "    # --- End Configuration ---\n",
        "\n",
        "    # Check if the path is STILL the placeholder\n",
        "    if resume_pdf_path == \"path/to/your/resume.pdf\":\n",
        "        # If it is, print the warning\n",
        "        print(\"=\"*60)\n",
        "        print(\"!! PLEASE UPDATE 'resume_pdf_path' in the script with the actual path to the PDF file. !!\")\n",
        "        print(\"=\"*60)\n",
        "    else:\n",
        "        # Otherwise (if you've changed it), run the interview\n",
        "        run_interview(resume_pdf_path)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing LLM with model: gemini-2.0-flash\n",
            "Loading resume: Sresume.pdf\n",
            "Resume text loaded, starting extraction...\n",
            "Invoking extraction chain...\n",
            "Extraction chain finished.\n",
            "Resume parsed successfully.\n",
            "\n",
            "Starting Interview Simulation for Shardul Pande...\n",
            "==============================\n",
            "\n",
            "--- Behavioral Question ---\n",
            "Interviewer: Tell me about a time you had to adapt your data analysis approach when you encountered unexpected data quality issues or limitations in the available data. What did you do and what was the outcome?\n",
            "Shardul Pande's Answer: I removed missing data and employed data cleaning and pre processing techniques to encounter this issues\n",
            "\n",
            "Interviewer: Thinking...\n",
            "Interviewer Feedback: While you mentioned relevant actions like removing missing data and cleaning, the answer lacks specifics. Use the STAR method to structure your response â€“ describe the Situation, Task, Action (with details on *how* you cleaned and what techniques you used), and Result (quantify the impact if possible). This will make your answer more compelling and demonstrate your problem-solving skills.\n",
            "--------------------\n",
            "\n",
            "--- Technical/Coding Concept Question ---\n",
            "Interviewer: Given your experience with both Pandas and SQL, imagine you need to perform a complex data transformation that involves grouping, filtering, and aggregating data. Describe a scenario where you would choose to perform this transformation using Pandas instead of SQL, and explain your reasoning behind that choice. Consider factors like data size, complexity of the transformation, and performance.\n",
            "Shardul Pande's Approach/Explanation: on a large data set as we can set various parameters in pandas to group, filter and aggregate the data\n",
            "\n",
            "Interviewer: Thinking...\n",
            "Interviewer Feedback: The answer is a bit vague. While mentioning parameters is relevant, it lacks specifics about *why* Pandas would be preferred in a complex scenario. Elaborate on the types of transformations or data characteristics that make Pandas a better choice than SQL, and perhaps touch upon specific Pandas features that would be advantageous.\n",
            "--------------------\n",
            "\n",
            "--- Behavioral Question ---\n",
            "Interviewer: Tell me about a time you had to convince a stakeholder to accept a data-driven recommendation that they were initially hesitant about. What approach did you take?\n",
            "Shardul Pande's Answer: Showed them graphical representation of data driven recommendation how it benefits the stake holder and convinced him to take data driven decision over emotional decision\n",
            "\n",
            "Interviewer: Thinking...\n",
            "Interviewer Feedback: This is a good start, but needs more detail. To really shine, use the STAR method: describe the Situation, your Task, the Action you took (be specific about your communication and persuasive techniques), and the Result. Adding specifics will make your answer more impactful.\n",
            "--------------------\n",
            "\n",
            "========================= Generating Final Feedback =========================\n",
            "\n",
            "==================== Final Interview Feedback for Shardul Pande ====================\n",
            "Okay, here is a comprehensive feedback summary for Shardul Pande based on the provided interview snippets:\n",
            "\n",
            "**1. Overall Summary:**\n",
            "\n",
            "Shardul demonstrates a foundational understanding of data analysis concepts and tools like Pandas and SQL. He recognizes the importance of data quality and data-driven decision-making. However, his responses lack sufficient detail and could benefit from more structured explanations, particularly when describing past experiences and technical reasoning. He needs to focus on providing concrete examples and elaborating on the \"how\" and \"why\" behind his actions.\n",
            "\n",
            "**2. Behavioral Section:**\n",
            "\n",
            "*   **Strengths:** Shardul understands the importance of data cleaning and pre-processing, as well as the need to persuade stakeholders with data.\n",
            "*   **Areas for Improvement:** Shardul's responses to behavioral questions need significant improvement. He needs to adopt the STAR method (Situation, Task, Action, Result) to provide more structured, detailed, and compelling answers. He should focus on providing specific examples of his actions and the impact they had. Instead of saying \"showed them graphical representation,\" he should describe *what* visualizations he used, *why* he chose them, and *how* they addressed the stakeholder's concerns.\n",
            "\n",
            "**3. Technical Concepts/Coding Section:**\n",
            "\n",
            "*   **Strengths:** Shardul is aware of Pandas' capabilities for grouping, filtering, and aggregating data.\n",
            "*   **Areas for Improvement:** Shardul's technical responses need more depth. He needs to articulate the specific reasons why Pandas might be preferred over SQL for certain complex data transformations. He should mention considerations such as the complexity of custom functions, the ease of handling unstructured data, or the advantages of in-memory processing for smaller datasets. He needs to be more precise and provide more detailed explanations.\n",
            "\n",
            "**4. System Design Section:**\n",
            "\n",
            "*   **Strengths:** (No questions were asked to evaluate this area)\n",
            "*   **Areas for Improvement:** (No questions were asked to evaluate this area)\n",
            "\n",
            "**5. Key Recommendations:**\n",
            "\n",
            "*   **Master the STAR Method:** Shardul *must* practice using the STAR method to answer behavioral questions. He should prepare examples beforehand, focusing on quantifying results whenever possible.\n",
            "*   **Provide Specific Examples:** In both behavioral and technical questions, avoid vague statements. Always provide specific examples to illustrate your points. This demonstrates a deeper understanding and practical experience.\n",
            "*   **Elaborate on \"Why\":** Focus on explaining the *reasoning* behind your choices. For technical questions, don't just state *what* you would do, but *why* you would choose that approach and what the trade-offs are.\n",
            "*   **Practice Technical Explanations:** Practice explaining technical concepts clearly and concisely. Consider using a whiteboard or online tool to walk through your thought process.\n",
            "*   **Review Pandas and SQL Best Practices:** Revisit the best practices for using Pandas and SQL for data transformation, paying attention to performance considerations and when to choose one over the other.\n",
            "*   **Prepare for Common Interview Questions:** Research common data analysis interview questions and prepare thorough, well-structured answers in advance.\n",
            "\n",
            "Shardul has potential, but needs to improve his ability to articulate his experiences and technical knowledge in a clear, detailed, and compelling manner. Focusing on the recommendations above will significantly improve his interview performance.\n",
            "========================================================\n",
            "\n",
            "Interview Simulation Complete.\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k1xgvVFUtEt",
        "outputId": "84e456c3-581c-4d69-926b-a76f04c1438f"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}